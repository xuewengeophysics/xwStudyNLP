# transformer

## 参考资料

论文1：[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)<br>
博客1：[Jay Alammar/The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer)<br>
博客2：[Miguel Romero Calvo/Dissecting BERT Part 1: The Encoder](https://medium.com/dissecting-bert/dissecting-bert-part-1-d3c3d495cdb3)<br>
博客3：[harvardnlp/The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)<br>

博客4：[张俊林/放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较](https://zhuanlan.zhihu.com/p/54743941)

博客5：[机器翻译模型Transformer代码详细解析](https://blog.csdn.net/mijiaoxiaosan/article/details/74909076)
博客5对应源码：[Kyubyong/transformer](https://github.com/Kyubyong/transformer)

博客6：[文本分类实战之Transformer模型](https://www.cnblogs.com/jiangxinyang/p/10210813.html)
博客6对应源码：[jiangxinyang227/textClassifier/Transformer](https://github.com/jiangxinyang227/textClassifier/tree/master/Transformer)<br>

源码1：[brightmart/text_classification/a07_Transformer](https://github.com/brightmart/text_classification/tree/master/a07_Transformer)
源码2：[pengming617/text_classification/model/transformer](https://github.com/pengming617/text_classification/tree/master/model/transformer)<br>


