# sequence to sequence

## 参考资料

[[1] Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., & Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation.](https://arxiv.org/abs/1406.1078.pdf)<br>

[[2] Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks.](https://arxiv.org/pdf/1409.3215.pdf)<br>

博客1：[完全图解RNN、RNN变体、Seq2Seq、Attention机制](https://www.leiphone.com/news/201709/8tDpwklrKubaecTa.html)

博客2：[自然语言处理中的Attention机制总结](https://blog.csdn.net/hahajinbu/article/details/81940355)
